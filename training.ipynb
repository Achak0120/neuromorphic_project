{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27708ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 100000 rows to firetest_data.csv\n",
      "Fire rows: 50279\n",
      "No-fire rows: 49721\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import snntorch as snn\n",
    "import matplotlib.pyplot as plt\n",
    "from snntorch import spikegen\n",
    "from snntorch import surrogate\n",
    "from snntorch import utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import csv\n",
    "from forest_fire_snn import SNN\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "025362e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Loss=0.2311 | Acc=0.903\n",
      "Epoch 2/50 | Loss=0.2086 | Acc=0.915\n",
      "Epoch 3/50 | Loss=0.2050 | Acc=0.916\n",
      "Epoch 4/50 | Loss=0.2025 | Acc=0.917\n",
      "Epoch 5/50 | Loss=0.1989 | Acc=0.918\n",
      "Epoch 6/50 | Loss=0.1966 | Acc=0.919\n",
      "Epoch 7/50 | Loss=0.1944 | Acc=0.919\n",
      "Epoch 8/50 | Loss=0.1931 | Acc=0.920\n",
      "Epoch 9/50 | Loss=0.1940 | Acc=0.919\n",
      "Epoch 10/50 | Loss=0.1927 | Acc=0.920\n",
      "Epoch 11/50 | Loss=0.1917 | Acc=0.920\n",
      "Epoch 12/50 | Loss=0.1904 | Acc=0.921\n",
      "Epoch 13/50 | Loss=0.1906 | Acc=0.920\n",
      "Epoch 14/50 | Loss=0.1895 | Acc=0.921\n",
      "Epoch 15/50 | Loss=0.1896 | Acc=0.921\n",
      "Epoch 16/50 | Loss=0.1896 | Acc=0.921\n",
      "Epoch 17/50 | Loss=0.1878 | Acc=0.921\n",
      "Epoch 18/50 | Loss=0.1886 | Acc=0.922\n",
      "Epoch 19/50 | Loss=0.1884 | Acc=0.921\n",
      "Epoch 20/50 | Loss=0.1883 | Acc=0.921\n",
      "Epoch 21/50 | Loss=0.1871 | Acc=0.921\n",
      "Epoch 22/50 | Loss=0.1871 | Acc=0.921\n",
      "Epoch 23/50 | Loss=0.1874 | Acc=0.921\n",
      "Epoch 24/50 | Loss=0.1879 | Acc=0.921\n",
      "Epoch 25/50 | Loss=0.1865 | Acc=0.922\n",
      "Epoch 26/50 | Loss=0.1875 | Acc=0.922\n",
      "Epoch 27/50 | Loss=0.1858 | Acc=0.923\n",
      "Epoch 28/50 | Loss=0.1860 | Acc=0.922\n",
      "Epoch 29/50 | Loss=0.1847 | Acc=0.922\n",
      "Epoch 30/50 | Loss=0.1846 | Acc=0.923\n",
      "Epoch 31/50 | Loss=0.1857 | Acc=0.922\n",
      "Epoch 32/50 | Loss=0.1859 | Acc=0.923\n",
      "Epoch 33/50 | Loss=0.1857 | Acc=0.922\n",
      "Epoch 34/50 | Loss=0.1853 | Acc=0.922\n",
      "Epoch 35/50 | Loss=0.1853 | Acc=0.921\n",
      "Epoch 36/50 | Loss=0.1853 | Acc=0.922\n",
      "Epoch 37/50 | Loss=0.1842 | Acc=0.922\n",
      "Epoch 38/50 | Loss=0.1851 | Acc=0.922\n",
      "Epoch 39/50 | Loss=0.1848 | Acc=0.922\n",
      "Epoch 40/50 | Loss=0.1837 | Acc=0.923\n",
      "Epoch 41/50 | Loss=0.1853 | Acc=0.922\n",
      "Epoch 42/50 | Loss=0.1838 | Acc=0.922\n",
      "Epoch 43/50 | Loss=0.1838 | Acc=0.922\n",
      "Epoch 44/50 | Loss=0.1845 | Acc=0.923\n",
      "Epoch 45/50 | Loss=0.1836 | Acc=0.923\n",
      "Epoch 46/50 | Loss=0.1845 | Acc=0.922\n",
      "Epoch 47/50 | Loss=0.1843 | Acc=0.923\n",
      "Epoch 48/50 | Loss=0.1840 | Acc=0.923\n",
      "Epoch 49/50 | Loss=0.1843 | Acc=0.923\n",
      "Epoch 50/50 | Loss=0.1843 | Acc=0.923\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of SNN Object\n",
    "net = SNN()\n",
    "\n",
    "# Prepare CSV data\n",
    "df = pd.read_csv('firetest_data.csv')\n",
    "features = df[['Temp', 'Audio', 'Humidity', 'CO2']]\n",
    "labels = df['Fire']\n",
    "\n",
    "# Normalize features\n",
    "df['Temp'] = df['Temp'] / 100\n",
    "df['Humidity'] = df['Humidity'] / 100\n",
    "df['CO2'] = df['CO2'] / 5000\n",
    "\n",
    "X = df[['Temp', 'Audio', 'Humidity', 'CO2']]\n",
    "Y = df['Fire'].to_numpy()\n",
    "\n",
    "X_np = X.to_numpy()\n",
    "Y_np = Y\n",
    "X_tensor = torch.tensor(X_np, dtype=torch.float32)\n",
    "X_tensor = X_tensor.clamp(0,1)\n",
    "Y_tensor = torch.tensor(Y_np, dtype=torch.long)\n",
    "\n",
    "# Convert features to spike trains\n",
    "num_steps = 25\n",
    "def to_spike_trains(X_tensor, num_steps=25):\n",
    "    num_samples, num_features = X_tensor.shape\n",
    "    spike_data = torch.zeros((num_samples, num_steps, num_features))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        for t in range(num_steps):\n",
    "            spike_data[i, t] = torch.bernoulli(X_tensor[i])\n",
    "    return spike_data\n",
    "\n",
    "fire_train = to_spike_trains(X_tensor, num_steps=num_steps)\n",
    "\n",
    "class FireDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, spike_data, labels):\n",
    "        self.spike_data = spike_data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.spike_data[idx], self.labels[idx]\n",
    "    \n",
    "dataset = FireDataset(fire_train, Y_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Training Loop\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_loss, total_correct, total_n = 0.0, 0, 0\n",
    "    \n",
    "    for data, targets in train_loader:\n",
    "        data = data.permute(1, 0, 2)\n",
    "        utils.reset(net)\n",
    "        spk_rec, mem_rec = net(data)\n",
    "        logits = spk_rec.sum(dim=0)\n",
    "        \n",
    "        loss = loss_fn(logits, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        bs = targets.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_correct += (logits.argmax(dim=1) == targets).sum().item()\n",
    "        total_n += bs\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss={total_loss/total_n:.4f} | Acc={total_correct/total_n:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef37e18",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval_acc_loss() missing 1 required positional argument: 'loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m             total_n += bs\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m total_loss/total_n, total_correct/total_n\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43meval_acc_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: eval_acc_loss() missing 1 required positional argument: 'loader'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch\n",
    "from snntorch import utils\n",
    "\n",
    "def make_train_val_loaders(dataset, batch_size=64, val_frac=0.2, seed=42):\n",
    "    n = len(dataset)\n",
    "    val_n = int(val_frac * n)\n",
    "    train_n = n - val_n\n",
    "\n",
    "    train_ds, val_ds = random_split(\n",
    "        dataset,\n",
    "        [train_n, val_n],\n",
    "        generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def eval_acc_loss(net, loader, loss_fn, device=None):\n",
    "    \"\"\"\n",
    "    net: your SNN model\n",
    "    loader: train_loader or val_loader\n",
    "    loss_fn: e.g. nn.CrossEntropyLoss()\n",
    "    device: optional torch.device; if provided, moves tensors to device\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    total_loss, total_correct, total_n = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in loader:\n",
    "            # data shape from dataset: (batch, time, features)\n",
    "            # you want: (time, batch, features)\n",
    "            data = data.permute(1, 0, 2)\n",
    "\n",
    "            if device is not None:\n",
    "                data = data.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "            utils.reset(net)\n",
    "            spk_rec, mem_rec = net(data)   # spk_rec: (time, batch, num_outputs)\n",
    "\n",
    "            logits = spk_rec.sum(dim=0)    # (batch, num_outputs)\n",
    "            loss = loss_fn(logits, targets)\n",
    "\n",
    "            bs = targets.size(0)\n",
    "            total_loss += loss.item() * bs\n",
    "            total_correct += (logits.argmax(dim=1) == targets).sum().item()\n",
    "            total_n += bs\n",
    "\n",
    "    return total_loss / total_n, total_correct / total_n\n",
    "\n",
    "\n",
    "train_loader, val_loader = make_train_val_loaders(dataset, batch_size=64, val_frac=0.2, seed=42)\n",
    "train_loss, train_acc = eval_acc_loss(net, train_loader, loss_fn)\n",
    "val_loss, val_acc     = eval_acc_loss(net, val_loader, loss_fn)\n",
    "print(f\"Train: loss={train_loss:.4f}, acc={train_acc:.3f} | Val: loss={val_loss:.4f}, acc={val_acc:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a933b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
